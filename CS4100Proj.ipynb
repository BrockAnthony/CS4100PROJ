{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87bc8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f21a89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to convert the images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((30, 30)), # Resize the image to 30x30 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root='archive/Training', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='archive/Testing', transform=transform)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2faba77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 30, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the size of the dataset and the shape of images\n",
    "num_images = len(train_dataset)\n",
    "image_shape = next(iter(train_loader))[0].shape[1:]  # CxHxW\n",
    "\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2720c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize numpy arrays for storing data and labels\n",
    "data_all = np.zeros((num_images,) + image_shape, dtype=np.float32)\n",
    "labels_all = np.zeros(num_images, dtype=np.int64)\n",
    "\n",
    "# Iterate over the DataLoader and fill the arrays\n",
    "start_idx = 0\n",
    "for images, labels in train_loader:\n",
    "    end_idx = start_idx + images.size(0)\n",
    "    data_all[start_idx:end_idx] = images.numpy()\n",
    "    labels_all[start_idx:end_idx] = labels.numpy()\n",
    "    start_idx = end_idx\n",
    "    \n",
    "# Now data_all is a NumPy array containing all images\n",
    "# and labels_all contains all corresponding labels\n",
    "# {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "188f30a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4569, 3, 30, 30) (1143, 3, 30, 30) (4569,) (1143,)\n"
     ]
    }
   ],
   "source": [
    "#splitting the training dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_all, labels_all, test_size=0.2, random_state=42)\n",
    "\n",
    "#printing the shape of the training and testing datasets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81b7d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainTumorClassifier, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)  # The input size here should match the output size of the last conv layer\n",
    "        self.fc2 = nn.Linear(512, 4)  # Output layer with 4 classes\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flattening the output for the dense layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layer with ReLU and dropout\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        \n",
    "        # Output layer with softmax activation\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def to_one_hot(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a38b523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot = to_one_hot(y_train, num_classes=4)\n",
    "y_test_one_hot = to_one_hot(y_test, num_classes=4)\n",
    "\n",
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "faef8731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 1.1527, Train Accuracy: 57.77%, Val Loss: 1.0992, Val Accuracy: 62.70%\n",
      "Epoch 2/25, Train Loss: 1.0383, Train Accuracy: 70.13%, Val Loss: 1.0847, Val Accuracy: 64.07%\n",
      "Epoch 3/25, Train Loss: 0.9821, Train Accuracy: 75.70%, Val Loss: 1.0092, Val Accuracy: 72.16%\n",
      "Epoch 4/25, Train Loss: 0.9470, Train Accuracy: 79.80%, Val Loss: 1.0029, Val Accuracy: 73.15%\n",
      "Epoch 5/25, Train Loss: 0.9187, Train Accuracy: 82.42%, Val Loss: 0.9664, Val Accuracy: 77.27%\n",
      "Epoch 6/25, Train Loss: 0.9017, Train Accuracy: 84.21%, Val Loss: 0.9737, Val Accuracy: 76.20%\n",
      "Epoch 7/25, Train Loss: 0.8956, Train Accuracy: 84.72%, Val Loss: 0.9344, Val Accuracy: 80.32%\n",
      "Epoch 8/25, Train Loss: 0.8801, Train Accuracy: 86.27%, Val Loss: 0.9304, Val Accuracy: 80.40%\n",
      "Epoch 9/25, Train Loss: 0.8624, Train Accuracy: 88.15%, Val Loss: 0.9106, Val Accuracy: 82.84%\n",
      "Epoch 10/25, Train Loss: 0.8431, Train Accuracy: 90.21%, Val Loss: 0.9012, Val Accuracy: 84.06%\n",
      "Epoch 11/25, Train Loss: 0.8340, Train Accuracy: 90.83%, Val Loss: 0.8853, Val Accuracy: 85.05%\n",
      "Epoch 12/25, Train Loss: 0.8272, Train Accuracy: 91.72%, Val Loss: 0.8753, Val Accuracy: 86.88%\n",
      "Epoch 13/25, Train Loss: 0.8142, Train Accuracy: 93.15%, Val Loss: 0.8708, Val Accuracy: 87.11%\n",
      "Epoch 14/25, Train Loss: 0.8117, Train Accuracy: 93.35%, Val Loss: 0.8766, Val Accuracy: 86.50%\n",
      "Epoch 15/25, Train Loss: 0.8082, Train Accuracy: 93.56%, Val Loss: 0.8580, Val Accuracy: 88.48%\n",
      "Epoch 16/25, Train Loss: 0.7987, Train Accuracy: 94.64%, Val Loss: 0.8624, Val Accuracy: 87.72%\n",
      "Epoch 17/25, Train Loss: 0.8029, Train Accuracy: 94.29%, Val Loss: 0.8770, Val Accuracy: 85.96%\n",
      "Epoch 18/25, Train Loss: 0.8018, Train Accuracy: 94.29%, Val Loss: 0.8566, Val Accuracy: 88.63%\n",
      "Epoch 19/25, Train Loss: 0.7955, Train Accuracy: 95.05%, Val Loss: 0.8525, Val Accuracy: 88.48%\n",
      "Epoch 20/25, Train Loss: 0.7942, Train Accuracy: 95.06%, Val Loss: 0.8451, Val Accuracy: 89.40%\n",
      "Epoch 21/25, Train Loss: 0.7918, Train Accuracy: 95.19%, Val Loss: 0.8567, Val Accuracy: 88.25%\n",
      "Epoch 22/25, Train Loss: 0.7939, Train Accuracy: 95.12%, Val Loss: 0.8343, Val Accuracy: 90.69%\n",
      "Epoch 23/25, Train Loss: 0.7900, Train Accuracy: 95.41%, Val Loss: 0.8244, Val Accuracy: 91.69%\n",
      "Epoch 24/25, Train Loss: 0.7787, Train Accuracy: 96.52%, Val Loss: 0.8212, Val Accuracy: 91.91%\n",
      "Epoch 25/25, Train Loss: 0.7838, Train Accuracy: 96.01%, Val Loss: 0.8306, Val Accuracy: 91.38%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = BrainTumorClassifier()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss applies softmax internally\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 25\n",
    "\n",
    "# Start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss_val = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_val += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_loss = running_loss_val / len(test_loader)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
